# ChaoqunWang
8.1:  
关于《Attention Is All You Need》提出的Transformer模型，有一篇非常详细的[解释(包含代码)](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

8.2:  
找到一份比较清晰的seq2seq的TensorFlow代码实现（用于生成歌词，未加入attention）